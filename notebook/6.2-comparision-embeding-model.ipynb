{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3787f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path setup to resolve package imports (dynamic project root)\n",
    "import sys, os\n",
    "\n",
    "# Derive project root from current notebook directory: <project>/notebook\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17aa496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell X: FETCH ‚Üí BUILD ‚Üí STORE ‚Üí QUERY COMPARE (Separate DBs per model)\n",
    "\n",
    "import time\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from src.db.db_schema_wrapper import db_schema_wrapper\n",
    "\n",
    "print(\"üîÑ FETCH ‚Üí BUILD ‚Üí STORE ‚Üí QUERY COMPARE (Separate DBs)\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# 1. FETCH (unchanged)\n",
    "def fetch_schema_documents(table_names=None):\n",
    "    if table_names is None:\n",
    "        table_names = db_schema_wrapper.get_usable_table_names().split(\", \")\n",
    "    \n",
    "    print(f\"üì• Fetching schemas for {len(table_names)} tables...\")\n",
    "    schema_docs = []\n",
    "    \n",
    "    for table in table_names:\n",
    "        schema_text = db_schema_wrapper.get_table_info([table])\n",
    "        doc = Document(\n",
    "            page_content=schema_text,\n",
    "            metadata={\"table\": table.strip(), \"type\": \"schema\", \"source\": \"db_wrapper\"}\n",
    "        )\n",
    "        schema_docs.append(doc)\n",
    "        print(f\"  ‚ûï {table}: {len(schema_text)} chars\")\n",
    "    \n",
    "    print(f\"‚úÖ Fetched {len(schema_docs)} schema documents\")\n",
    "    return schema_docs\n",
    "\n",
    "# 2. BUILD & STORE separate DBs for each model\n",
    "def build_and_store_model_dbs(schema_docs, models_config):\n",
    "    \"\"\"Build + save separate vector DB for each embedding model\"\"\"\n",
    "    \n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
    "    split_docs = splitter.split_documents(schema_docs)\n",
    "    \n",
    "    model_dbs = {}\n",
    "    \n",
    "    print(f\"\\nüèóÔ∏è  Building {len(models_config)} separate vector DBs...\")\n",
    "    \n",
    "    for model_name, (embeddings_class, model_id, folder) in models_config.items():\n",
    "        print(f\"\\nüî® {model_name}...\")\n",
    "        \n",
    "        # Create embeddings\n",
    "        if embeddings_class == OpenAIEmbeddings:\n",
    "            embeddings = embeddings_class(model=model_id)\n",
    "        else:  # Ollama\n",
    "            embeddings = embeddings_class(model=model_id)\n",
    "        \n",
    "        # Build DB\n",
    "        start_time = time.time()\n",
    "        db = FAISS.from_documents(split_docs, embeddings)\n",
    "        build_time = time.time() - start_time\n",
    "        \n",
    "        # Store separately\n",
    "        db.save_local(folder)\n",
    "        model_dbs[model_name] = {\n",
    "            \"db\": db,\n",
    "            \"embeddings\": embeddings,\n",
    "            \"folder\": folder,\n",
    "            \"chunks\": db.index.ntotal,\n",
    "            \"build_time\": build_time\n",
    "        }\n",
    "        \n",
    "        print(f\"   ‚úÖ Saved {db.index.ntotal} chunks ‚Üí {folder}/ ({build_time:.2f}s)\")\n",
    "    \n",
    "    return model_dbs\n",
    "\n",
    "# 3. LOAD & QUERY COMPARE (using saved DBs)\n",
    "def query_compare_saved_dbs(model_dbs, test_queries, k=3):\n",
    "    \"\"\"Query comparison using PRE-BUILT saved vector DBs\"\"\"\n",
    "    \n",
    "    print(f\"\\nüîç Query comparison ({len(test_queries)} queries)...\")\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for model_name, data in model_dbs.items():\n",
    "        print(f\"\\n‚ö° Querying {model_name} DB...\")\n",
    "        \n",
    "        db = data[\"db\"]\n",
    "        embeddings = data[\"embeddings\"]\n",
    "        \n",
    "        query_results = {}\n",
    "        total_query_time = 0\n",
    "        \n",
    "        for query in test_queries:\n",
    "            q_start = time.time()\n",
    "            \n",
    "            # Load DB if needed (production usage)\n",
    "            # db = FAISS.load_local(data[\"folder\"], embeddings, allow_dangerous_deserialization=True)\n",
    "            \n",
    "            docs_scores = db.similarity_search_with_score(query, k=k)\n",
    "            q_time = time.time() - q_start\n",
    "            \n",
    "            best_score = docs_scores[0][1] if docs_scores else 999\n",
    "            avg_score = sum(score for _, score in docs_scores) / k\n",
    "            \n",
    "            query_results[query] = {\n",
    "                \"best_score\": best_score,\n",
    "                \"avg_score\": avg_score,\n",
    "                \"top_tables\": [doc.metadata.get(\"table\", \"?\") for doc, _ in docs_scores],\n",
    "                \"top_docs\": [doc.page_content[:60] + \"...\" for doc, _ in docs_scores],\n",
    "                \"query_time\": q_time\n",
    "            }\n",
    "            total_query_time += q_time\n",
    "        \n",
    "        avg_query_time = total_query_time / len(test_queries)\n",
    "        results[model_name] = {\n",
    "            \"avg_query_time\": avg_query_time,\n",
    "            \"queries\": query_results,\n",
    "            \"overall_best\": min(r[\"best_score\"] for r in query_results.values()),\n",
    "            \"overall_avg\": sum(r[\"avg_score\"] for r in query_results.values()) / len(test_queries)\n",
    "        }\n",
    "        \n",
    "        print(f\"   ‚è±Ô∏è Avg query: {avg_query_time:.3f}s | Overall: {results[model_name]['overall_avg']:.3f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 4. MAIN EXECUTION\n",
    "test_queries = [\n",
    "    \"Show top customers by sales\",\n",
    "    \"employees in sales department\", \n",
    "    \"monthly revenue by region\",\n",
    "    \"customer lifetime value\",\n",
    "    \"active orders this quarter\"\n",
    "]\n",
    "\n",
    "# FETCH schemas\n",
    "schema_docs = fetch_schema_documents()\n",
    "\n",
    "# MODEL CONFIG (name ‚Üí class+id+folder)\n",
    "models_config = {\n",
    "    \"üîµ OpenAI-3-small\": (OpenAIEmbeddings, \"text-embedding-3-small\", \"db_openai_small\"),\n",
    "    \"üü¢ Ollama-nomic\": (OllamaEmbeddings, \"nomic-embed-text\", \"db_ollama_nomic\"),\n",
    "    # \"üü¢ Ollama-mxbai\": (OllamaEmbeddings, \"mxbai-embed-large\", \"db_ollama_mxbai\"),\n",
    "}\n",
    "\n",
    "# BUILD & STORE separate DBs\n",
    "model_dbs = build_and_store_model_dbs(schema_docs, models_config)\n",
    "\n",
    "# QUERY COMPARE using saved DBs\n",
    "query_results = query_compare_saved_dbs(model_dbs, test_queries)\n",
    "\n",
    "# 5. RANKING TABLE\n",
    "print(\"\\n\" + \"=\"*110)\n",
    "print(\"üèÜ PRODUCTION QUERY RANKING (Lower scores = BETTER relevance)\")\n",
    "print(\"=\"*110)\n",
    "\n",
    "print(f\"{'Model':<20} {'Overall Avg':<12} {'Best Query':<12} {'Query Time':<12} {'Top Tables'}\")\n",
    "print(\"-\"*110)\n",
    "\n",
    "ranked = sorted(query_results.items(), key=lambda x: x[1][\"overall_avg\"])\n",
    "medals = [\"ü•á\", \"ü•à\", \"ü•â\"]\n",
    "\n",
    "for i, (model_name, data) in enumerate(ranked):\n",
    "    medal = medals[i] if i < 3 else \"\"\n",
    "    best_query_score = data[\"overall_best\"]\n",
    "    sample_tables = \", \".join(data[\"queries\"][test_queries[0]][\"top_tables\"][:2])\n",
    "    \n",
    "    print(f\"{medal} {model_name:<18} {data['overall_avg']:<11.3f} \"\n",
    "          f\"{best_query_score:<11.3f} {data['avg_query_time']:<11.3f}s \"\n",
    "          f\"{sample_tables}\")\n",
    "\n",
    "winner_name = ranked[0][0]\n",
    "print(f\"\\nüéâ PRODUCTION WINNER: {winner_name}\")\n",
    "print(f\"   Use folder: {model_dbs[winner_name]['folder']}/\")\n",
    "\n",
    "# 6. SAVE WINNER AS DEFAULT\n",
    "print(f\"\\nüíæ Saved DB folders:\")\n",
    "for name, data in model_dbs.items():\n",
    "    print(f\"   {data['folder']}/ ‚Üê {data['chunks']} chunks ({name})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
