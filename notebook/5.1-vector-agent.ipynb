{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e2beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path setup to resolve package imports (dynamic project root)\n",
    "import sys, os\n",
    "\n",
    "# Derive project root from current notebook directory: <project>/notebook\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc14a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: VECTOR DB SETUP + INDEXING\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from src.db.db_schema_wrapper import db_schema_wrapper\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "print(\"üóÉÔ∏è Setting up Vector DB for schemas...\")\n",
    "\n",
    "# 1. Extract ALL schema info\n",
    "all_tables = db_schema_wrapper.get_usable_table_names().split(\", \")\n",
    "print(f\"üìä Indexing {len(all_tables)} tables...\")\n",
    "\n",
    "# 2. Get schema docs for ALL tables\n",
    "schema_docs = []\n",
    "for table in all_tables:  # Limit for demo\n",
    "    schema_text = db_schema_wrapper.get_table_info([table])\n",
    "    doc = Document(\n",
    "        page_content=schema_text,\n",
    "        metadata={\"table\": table, \"type\": \"schema\"}\n",
    "    )\n",
    "    schema_docs.append(doc)\n",
    "\n",
    "# 3. Create embeddings + split long schemas\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
    "\n",
    "split_docs = splitter.split_documents(schema_docs)\n",
    "\n",
    "# 4. Build vector store\n",
    "vector_db = FAISS.from_documents(split_docs, embeddings)\n",
    "print(f\"‚úÖ Vector DB ready: {vector_db.index.ntotal} chunks\")\n",
    "\n",
    "# Save for reuse\n",
    "vector_db.save_local(\"schema_vector_db\")\n",
    "print(\"üíæ Saved to schema_vector_db/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a402a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.agents.tools.db_tools import db_tool_manager\n",
    "# Test tool manager\n",
    "tools = db_tool_manager.get_tools()\n",
    "print(f\"‚úÖ {len(tools)} tools ready\")\n",
    "print(\"Tool names:\", [t.name for t in tools])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa6e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: VECTOR SEARCH TOOLS\n",
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def semantic_table_search(query: str, k: int = 3) -> str:\n",
    "    \"\"\"Find most relevant tables by semantic search on schemas\"\"\"\n",
    "    print(f\"üîç Semantic search: '{query}'\")\n",
    "    \n",
    "    # Vector search on schemas\n",
    "    relevant_docs = vector_db.similarity_search(query, k=k)\n",
    "    \n",
    "    results = []\n",
    "    for doc in relevant_docs:\n",
    "        table = doc.metadata['table']\n",
    "        score = 1.0 - doc.metadata.get('score', 0.5)  # Convert distance to similarity\n",
    "        results.append(f\"{table} (similarity: {score:.2f})\")\n",
    "    \n",
    "    return f\"Top {k} tables for '{query}':\\n\" + \"\\n\".join(results)\n",
    "\n",
    "@tool\n",
    "def get_schema_by_semantic_search(query: str) -> str:\n",
    "    \"\"\"Get schema for semantically relevant tables\"\"\"\n",
    "    print(f\"üìã Semantic schema search: '{query}'\")\n",
    "    \n",
    "    docs = vector_db.similarity_search(query, k=2)\n",
    "    tables = [doc.metadata['table'] for doc in docs]\n",
    "    \n",
    "    schema_info = db_schema_wrapper.get_table_info(tables)\n",
    "    return schema_info\n",
    "\n",
    "# Add to your existing tools\n",
    "VECTOR_TOOLS = [semantic_table_search, get_schema_by_semantic_search]\n",
    "ALL_TOOLS = tools + VECTOR_TOOLS  # Combine with your SQL tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f63ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: VECTOR-POWERED AGENT\n",
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from src.config.prompt import system_prompt\n",
    "\n",
    "# Vector-powered agent\n",
    "vector_llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "vector_checkpointer = MemorySaver()\n",
    "\n",
    "vector_agent = create_agent(\n",
    "    model=vector_llm,\n",
    "    tools=ALL_TOOLS,\n",
    "    system_prompt=system_prompt + \"\"\"ü§ñ VECTOR + SQL AGENT\n",
    "\n",
    "NEW TOOLS:\n",
    "1Ô∏è‚É£ semantic_table_search(\"sales customers\") ‚Üí Find relevant tables\n",
    "2Ô∏è‚É£ get_schema_by_semantic_search(\"sales customers\") ‚Üí Get schemas semantically\n",
    "\n",
    "Then use regular SQL tools. ALWAYS start with semantic search!\"\"\",\n",
    "    checkpointer=vector_checkpointer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6c6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: VECTOR SEARCH TEST\n",
    "print(\"üß™ Vector Search Examples\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test semantic search\n",
    "print(\"\\n1. üîç 'sales customers':\")\n",
    "print(semantic_table_search.invoke({\"query\": \"sales customers\", \"k\": 3}))\n",
    "\n",
    "print(\"\\n2. üîç 'employee department':\") \n",
    "print(semantic_table_search.invoke({\"query\": \"employee department\", \"k\": 3}))\n",
    "\n",
    "print(\"\\n3. üìã Full schema by similarity:\")\n",
    "print(get_schema_by_semantic_search.invoke({\"query\": \"sales customers\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a9058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: VECTOR AGENT STREAMING TEST\n",
    "from langchain_core.messages import AIMessage  # Add this import\n",
    "\n",
    "def stream_vector_agent(question):\n",
    "    \"\"\"Test vector-powered agent\"\"\"\n",
    "    config = {\"configurable\": {\"thread_id\": \"vector_test\"}}\n",
    "    \n",
    "    print(f\"\\nüöÄ Vector Agent: '{question}'\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for chunk in vector_agent.stream(\n",
    "        {\"messages\": [HumanMessage(content=question)]},\n",
    "        config,\n",
    "        stream_mode=\"values\"\n",
    "    ):\n",
    "        if \"messages\" in chunk:\n",
    "            msg = chunk[\"messages\"][-1]\n",
    "            \n",
    "            # ‚úÖ FIXED: Only check AIMessage for tool_calls\n",
    "            if isinstance(msg, AIMessage):\n",
    "                if msg.tool_calls:\n",
    "                    tool_name = msg.tool_calls[0]['name']\n",
    "                    print(f\"üü° {tool_name}: {msg.tool_calls[0]['args']}\")\n",
    "                if msg.content:\n",
    "                    print(msg.content, end=\"\", flush=True, sep=\"\")\n",
    "            # HumanMessage has no tool_calls - skip safely\n",
    "    \n",
    "    print(\"\\n‚úÖ Complete!\")\n",
    "# Test natural language ‚Üí vector ‚Üí SQL flow\n",
    "stream_vector_agent(\"Show top customers by sales\")\n",
    "stream_vector_agent(\"How many employees in sales department?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dac724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See ALL documents in your vectorstore\n",
    "all_docs = vector_db.similarity_search(\"anything\", k=1000)  # k=big number\n",
    "for i, doc in enumerate(all_docs):\n",
    "    print(f\"{i+1}. {doc.page_content[:500]}...\")\n",
    "    print(f\"   Metadata: {doc.metadata}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
