{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3758277a",
   "metadata": {},
   "source": [
    "## Agent with Automatic Memory Persistence\n",
    "\n",
    "Using LangGraph's MemorySaver, the agent automatically remembers conversation context without manual history management."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25620b3",
   "metadata": {},
   "source": [
    "# LangChain Agents with Persistent Memory (Checkpointer)\n",
    "\n",
    "This notebook demonstrates how to use LangGraph's checkpointer for automatic conversation memory persistence.\n",
    "\n",
    "## Key Concepts:\n",
    "- **MemorySaver**: Automatically saves conversation state\n",
    "- **thread_id**: Identifies different conversation threads\n",
    "- **Stateful Agents**: Agents that remember context across separate invocations\n",
    "- **No Manual History Management**: Unlike notebook 2.1, memory is automatic\n",
    "\n",
    "## Why Use Checkpointer?\n",
    "- Conversations persist even when agent is recreated\n",
    "- No need to manually track message history\n",
    "- Supports multiple concurrent conversations (different thread_ids)\n",
    "- Production-ready memory management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a4773f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a checkpointer for automatic memory persistence\n",
    "# This saves conversation state across agent invocations\n",
    "checkpointer = MemorySaver()\n",
    "\n",
    "# Define a simple tool for the agent\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get current weather for a city.\"\"\"\n",
    "    return f\"Weather in {city}: 72Â°F, sunny\"\n",
    "\n",
    "# Initialize language models\n",
    "gptLLM = ChatOpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "ollamaLLM = ChatOllama(model=\"llama3-groq-tool-use\")\n",
    "\n",
    "# Create agent WITH checkpointer for memory persistence\n",
    "agent = create_agent(\n",
    "    model=ollamaLLM,\n",
    "    tools=[get_weather],\n",
    "    system_prompt=\"You are a helpful assistant.\",\n",
    "    checkpointer=checkpointer  # KEY: Automatically saves state\n",
    ")\n",
    "\n",
    "# Configuration with thread_id to identify this conversation\n",
    "# Different thread_ids = different conversation memories\n",
    "config = {\"configurable\": {\"thread_id\": \"user_123\"}}\n",
    "\n",
    "# First invocation: User introduces themselves and asks about weather\n",
    "result1 = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"My Name is Ron. What's the weather like in New York City?\")]},\n",
    "    config  # Pass thread_id to save conversation state\n",
    ")\n",
    "print(\"First message response:\")\n",
    "print(result1[\"messages\"][-1].content)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Second invocation (could be minutes or days later!)\n",
    "# The agent remembers the previous conversation because:\n",
    "# 1. Same thread_id is used\n",
    "# 2. Checkpointer automatically loaded saved state\n",
    "result2 = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What is my Name?\")]},\n",
    "    config  # Same thread_id = retrieves saved memory\n",
    ")\n",
    "print(\"Second message response:\")\n",
    "print(result2[\"messages\"][-1].content)\n",
    "# Expected: Agent remembers \"Ron\" from the previous turn!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
