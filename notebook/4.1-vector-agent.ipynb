{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6285565",
   "metadata": {},
   "source": [
    "# ğŸš€ Vector-Powered Database Query Agent\n",
    "\n",
    "## ğŸ“‹ Overview\n",
    "This notebook demonstrates building an intelligent database query agent that uses **semantic search** to understand natural language questions and find relevant database tables before executing SQL queries.\n",
    "\n",
    "\n",
    "\n",
    "## ğŸ¯ Key Components\n",
    "1. **Chroma Vector Store**: Indexes database schemas for fast semantic search\n",
    "2. **Embedding Model**: Converts table schemas to vector representations\n",
    "3. **Custom Tools**: Semantic search tools for table discovery\n",
    "4. **ReAct Agent**: Combines reasoning with tool usage for intelligent querying\n",
    "\n",
    "## ğŸ“ Notebook Structure\n",
    "- **Cell 1**: Build and index vector database from schema\n",
    "- **Cell 2**: Clean up corrupted vector DB (maintenance)\n",
    "- **Cell 3**: Load existing vector database (fast start)\n",
    "- **Cell 4**: Define custom vector search tools\n",
    "- **Cell 5**: Create vector-powered agent\n",
    "- **Cell 6**: Test vector search tools\n",
    "- **Cell 7**: Test complete agent with questions\n",
    "- **Cell 8**: Inspect vector store contents\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "250e2beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Project root added to path: c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SETUP: Path Configuration for Module Imports\n",
    "# ============================================================================\n",
    "# Add project root to Python path to enable imports from src/ directory\n",
    "\n",
    "import sys, os\n",
    "\n",
    "# Derive project root from current notebook directory: <project>/notebook\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "\n",
    "# Add to sys.path if not already present\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    \n",
    "print(f\"âœ… Project root added to path: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213823de",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š Step 1: Build & Index Vector Database\n",
    "\n",
    "This cell creates a vector database of all table schemas for semantic search.\n",
    "\n",
    "### What This Does:\n",
    "1. **Connects to Database**: Uses configured database tools\n",
    "2. **Extracts Schemas**: Gets CREATE TABLE statements for all tables\n",
    "3. **Fetches Sample Data**: Retrieves first 3 rows from each table (best-effort)\n",
    "4. **Creates Documents**: Converts each table into a searchable document\n",
    "5. **Generates Embeddings**: Converts schemas to vector representations\n",
    "6. **Stores in Chroma**: Persists to disk for fast retrieval\n",
    "\n",
    "### When to Run:\n",
    "- **First time**: Initial setup\n",
    "- **After schema changes**: New tables, columns, or relationships\n",
    "- **Database migration**: Moving to new database\n",
    "- **Corrupted vector store**: After cleanup in Cell 2\n",
    "\n",
    "### Performance:\n",
    "- Takes ~2-5 minutes for 50-100 tables\n",
    "- Only needs to run once (results are persisted)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46f3110",
   "metadata": {},
   "source": [
    "## ğŸ”§ Setup: Environment Configuration\n",
    "\n",
    "This cell configures the Python path to enable imports from the `src/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc14a969",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\\.venv\\lib\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.11) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "INFO: Found 14 tables\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—ƒï¸ Setting up Vector DB for database schemas...\n",
      "âš ï¸ Warning: Vector DB directory 'src/vectors/db_schema_vectors' already exists and is not empty.\n",
      "ğŸ” Raw output: ['public.categories', 'public.customer_customer_demo', 'public.customer_demographics', 'public.customers', 'public.employee_territories', 'public.employees', 'public.order_details', 'public.orders', 'public.products', 'public.region', 'public.shippers', 'public.suppliers', 'public.territories', 'public.us_states']\n",
      "âœ… Found 14 tables:\n",
      "   â€¢ public.categories\n",
      "   â€¢ public.customer_customer_demo\n",
      "   â€¢ public.customer_demographics\n",
      "   â€¢ public.customers\n",
      "   â€¢ public.employee_territories\n",
      "   â€¢ public.employees\n",
      "   â€¢ public.order_details\n",
      "   â€¢ public.orders\n",
      "   â€¢ public.products\n",
      "   â€¢ public.region\n",
      "   â€¢ public.shippers\n",
      "   â€¢ public.suppliers\n",
      "   â€¢ public.territories\n",
      "   â€¢ public.us_states\n",
      "[1/14] Processing: public.categories... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Retrieved schema for: public.categories\n",
      "INFO: Retrieved schema for: public.customer_customer_demo\n",
      "INFO: Retrieved schema for: public.customer_demographics\n",
      "INFO: Retrieved schema for: public.customers\n",
      "INFO: Retrieved schema for: public.employee_territories\n",
      "INFO: Retrieved schema for: public.employees\n",
      "INFO: Retrieved schema for: public.order_details\n",
      "INFO: Retrieved schema for: public.orders\n",
      "INFO: Retrieved schema for: public.products\n",
      "INFO: Retrieved schema for: public.region\n",
      "INFO: Retrieved schema for: public.shippers\n",
      "INFO: Retrieved schema for: public.suppliers\n",
      "INFO: Retrieved schema for: public.territories\n",
      "INFO: Retrieved schema for: public.us_states\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data fetched. \n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "[(1, 'Beverages', 'Soft drinks, coffees, teas, beers, and ales', <memory at 0x000001EACA5EBB80>), (2, 'Condiments', 'Sweet and savory sauces, relishes, spreads, and seasonings', <memory at 0x000001EACA5EB940>), (3, 'Confections', 'Desserts, candies, and sweet breads', <memory at 0x000001EACA5EBC40>)]\n",
      "âœ“\n",
      "[2/14] Processing: public.customer_customer_demo... Sample data fetched. \n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "\n",
      "âœ“\n",
      "[3/14] Processing: public.customer_demographics... Sample data fetched. \n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "\n",
      "âœ“\n",
      "[4/14] Processing: public.customers... Sample data fetched. \n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "[('ALFKI', 'Alfreds Futterkiste', 'Maria Anders', 'Sales Representative', 'Obere Str. 57', 'Berlin', None, '12209', 'Germany', '030-0074321', '030-0076545'), ('ANATR', 'Ana Trujillo Emparedados y helados', 'Ana Trujillo', 'Owner', 'Avda. de la ConstituciÃ³n 2222', 'MÃ©xico D.F.', None, '05021', 'Mexico', '(5) 555-4729', '(5) 555-3745'), ('ANTON', 'Antonio Moreno TaquerÃ­a', 'Antonio Moreno', 'Owner', 'Mataderos  2312', 'MÃ©xico D.F.', None, '05023', 'Mexico', '(5) 555-3932', None)]\n",
      "âœ“\n",
      "[5/14] Processing: public.employee_territories... Sample data fetched. \n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "[(1, '06897'), (1, '19713'), (2, '01581')]\n",
      "âœ“\n",
      "[6/14] Processing: public.employees... Sample data fetched. \n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "[(1, 'Davolio', 'Nancy', 'Sales Representative', 'Ms.', datetime.date(1948, 12, 8), datetime.date(1992, 5, 1), '507 - 20th Ave. E.\\\\nApt. 2A', 'Seattle', 'WA', '98122', 'USA', '(206) 555-9857', '5467', <memory at 0x000001EACA5EBF40>, 'Education includes a BA in psychology from Colorado State University in 1970.  She also completed The Art of the Cold Call.  Nancy is a member of Toastmasters International.', 2, 'http://accweb/emmployees/davolio.bmp'), (2, 'Fuller', 'Andrew', 'Vice President, Sales', 'Dr.', datetime.date(1952, 2, 19), datetime.date(1992, 8, 14), '908 W. Capital Way', 'Tacoma', 'WA', '98401', 'USA', '(206) 555-9482', '3457', <memory at 0x000001EACB84C100>, 'Andrew received his BTS commercial in 1974 and a Ph.D. in international marketing from the University of Dallas in 1981.  He is fluent in French and Italian and reads German.  He joined the company as a sales representative, was promoted to sales manager in January 1992 and to vice president of...', None, 'http://accweb/emmployees/fuller.bmp'), (3, 'Leverling', 'Janet', 'Sales Representative', 'Ms.', datetime.date(1963, 8, 30), datetime.date(1992, 4, 1), '722 Moss Bay Blvd.', 'Kirkland', 'WA', '98033', 'USA', '(206) 555-3412', '3355', <memory at 0x000001EACB84C280>, 'Janet has a BS degree in chemistry from Boston College (1984).  She has also completed a certificate program in food retailing management.  Janet was hired as a sales associate in 1991 and promoted to sales representative in February 1992.', 2, 'http://accweb/emmployees/leverling.bmp')]\n",
      "âœ“\n",
      "[7/14] Processing: public.order_details... Sample data fetched. \n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "[(10248, 11, 14.0, 12, 0.0), (10248, 42, 9.8, 10, 0.0), (10248, 72, 34.8, 5, 0.0)]\n",
      "âœ“\n",
      "[8/14] Processing: public.orders... Sample data fetched. \n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "[(10248, 'VINET', 5, datetime.date(1996, 7, 4), datetime.date(1996, 8, 1), datetime.date(1996, 7, 16), 3, 32.38, 'Vins et alcools Chevalier', \"59 rue de l'Abbaye\", 'Reims', None, '51100', 'France'), (10249, 'TOMSP', 6, datetime.date(1996, 7, 5), datetime.date(1996, 8, 16), datetime.date(1996, 7, 10), 1, 11.61, 'Toms SpezialitÃ¤ten', 'Luisenstr. 48', 'MÃ¼nster', None, '44087', 'Germany'), (10250, 'HANAR', 4, datetime.date(1996, 7, 8), datetime.date(1996, 8, 5), datetime.date(1996, 7, 12), 2, 65.83, 'Hanari Carnes', 'Rua do PaÃ§o, 67', 'Rio de Janeiro', 'RJ', '05454-876', 'Brazil')]\n",
      "âœ“\n",
      "[9/14] Processing: public.products... Sample data fetched. \n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "[(1, 'Chai', 8, 1, '10 boxes x 30 bags', 18.0, 39, 0, 10, 1), (2, 'Chang', 1, 1, '24 - 12 oz bottles', 19.0, 17, 40, 25, 1), (3, 'Aniseed Syrup', 1, 2, '12 - 550 ml bottles', 10.0, 13, 70, 25, 0)]\n",
      "âœ“\n",
      "[10/14] Processing: public.region... Sample data fetched. \n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "[(1, 'Eastern'), (2, 'Western'), (3, 'Northern')]\n",
      "âœ“\n",
      "[11/14] Processing: public.shippers... Sample data fetched. \n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "[(1, 'Speedy Express', '(503) 555-9831'), (2, 'United Package', '(503) 555-3199'), (3, 'Federal Shipping', '(503) 555-9931')]\n",
      "âœ“\n",
      "[12/14] Processing: public.suppliers... Sample data fetched. \n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "[(1, 'Exotic Liquids', 'Charlotte Cooper', 'Purchasing Manager', '49 Gilbert St.', 'London', None, 'EC1 4SD', 'UK', '(171) 555-2222', None, None), (2, 'New Orleans Cajun Delights', 'Shelley Burke', 'Order Administrator', 'P.O. Box 78934', 'New Orleans', 'LA', '70117', 'USA', '(100) 555-4822', None, '#CAJUN.HTM#'), (3, \"Grandma Kelly's Homestead\", 'Regina Murphy', 'Sales Representative', '707 Oxford Rd.', 'Ann Arbor', 'MI', '48104', 'USA', '(313) 555-5735', '(313) 555-3349', None)]\n",
      "âœ“\n",
      "[13/14] Processing: public.territories... Sample data fetched. \n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "[('01581', 'Westboro', 1), ('01730', 'Bedford', 1), ('01833', 'Georgetow', 1)]\n",
      "âœ“\n",
      "[14/14] Processing: public.us_states... Sample data fetched. \n",
      "\n",
      "Sample Data (first 3 rows):\n",
      "[(1, 'Alabama', 'AL', 'south'), (2, 'Alaska', 'AK', 'north'), (3, 'Arizona', 'AZ', 'west')]\n",
      "âœ“\n",
      "\n",
      "âœ… Successfully created 14 schema documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Vector DB ready: 14 documents indexed\n",
      "ğŸ’¾ Persisted to: src/vectors/db_schema_vectors/db_schema_postgres_northwind\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š PROCESSING SUMMARY\n",
      "======================================================================\n",
      "âœ… Successful: 14/14\n",
      "âŒ Failed: 0/14\n",
      "ğŸ“¦ Total Documents Indexed: 14\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL 1: BUILD & INDEX VECTOR DATABASE\n",
    "# ============================================================================\n",
    "# This cell creates a vector database of all table schemas for semantic search\n",
    "# Run this once to build the index, then use Cell 3 to load existing DB\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from src.db.db_client import db_client\n",
    "from src.config.models import get_llm, get_vector_embeddings\n",
    "from src.agents.tools import db_tool_manager\n",
    "from src.config.vector_config import VECTOR_DB_SCHEMA_DIR, VECTOR_DB_SCHEMA_NAME\n",
    "import os\n",
    "import warnings\n",
    "import re\n",
    "\n",
    "# Suppress SQLAlchemy warnings about SQL Server data types\n",
    "warnings.filterwarnings('ignore', message='.*Did not recognize type.*')\n",
    "warnings.filterwarnings('ignore', category=Warning, module='sqlalchemy')\n",
    "\n",
    "print(\"ğŸ—ƒï¸ Setting up Vector DB for database schemas...\")\n",
    "\n",
    "if True:\n",
    "    print(f\"âš ï¸ Warning: Vector DB directory '{VECTOR_DB_SCHEMA_DIR}' already exists and is not empty.\")\n",
    "    \n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Step 1: Initialize LLM and Database Tools\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    llm = get_llm()\n",
    "    tools = db_tool_manager.get_tools(llm=llm)\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Step 2: Identify Required SQL Tools\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # We need three specific tools for schema extraction:\n",
    "    # - list_all_tables: Get all table names in the database\n",
    "    # - sql_db_schema: Get CREATE TABLE statements and structure\n",
    "    # - sql_db_query: Execute queries to fetch sample data\n",
    "\n",
    "    list_tables_tool = None\n",
    "    schema_tool = None\n",
    "    query_tool = None\n",
    "\n",
    "    for tool in tools:\n",
    "        if tool.name == \"list_all_tables\":\n",
    "            list_tables_tool = tool\n",
    "        elif tool.name == \"get_table_schema\":\n",
    "            schema_tool = tool \n",
    "        elif tool.name == \"sql_db_query\":\n",
    "            query_tool = tool\n",
    "\n",
    "    if not list_tables_tool or not schema_tool:\n",
    "        raise RuntimeError(\"âŒ Required SQL tools are missing\")\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Step 3: Extract and Parse Table Names\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Get raw list of tables (may be string or list format)\n",
    "    table_names_str = list_tables_tool.invoke(\"\")\n",
    "    print(f\"ğŸ” Raw output: {repr(table_names_str)}\")  # Debug output\n",
    "\n",
    "    # Handle both list and string responses\n",
    "    if isinstance(table_names_str, list):\n",
    "        table_names = table_names_str\n",
    "    else:\n",
    "        cleaned = re.sub(r'^[\\[\\(\\{\\'\\\"]+|[\\]\\)\\}\\'\\\"]+$', '', table_names_str.strip())\n",
    "        # Split by comma and clean each name\n",
    "        table_names = [\n",
    "            name.strip().strip('()[]{}\\'\\\"') \n",
    "            for name in cleaned.split(',')\n",
    "            if name.strip() and name.strip().strip('()[]{}\\'\\\"')\n",
    "        ]\n",
    "\n",
    "    print(f\"âœ… Found {len(table_names)} tables:\")\n",
    "    for tn in table_names:\n",
    "        print(f\"   â€¢ {tn}\")\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Step 4: Build Document Collection from Database Schemas\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Each table becomes a Document with:\n",
    "    # - page_content: Schema definition + sample data\n",
    "    # - metadata: Table name, source, type\n",
    "\n",
    "    schema_docs = []\n",
    "    failed_tables = []\n",
    "    success_count = 0\n",
    "\n",
    "    for idx, table_name in enumerate(table_names, 1):\n",
    "        try:\n",
    "            print(f\"[{idx}/{len(table_names)}] Processing: {table_name}...\", end=\" \")\n",
    "            \n",
    "            # Get CREATE TABLE statement and column definitions\n",
    "            table_info = schema_tool.invoke(table_name)\n",
    "            \n",
    "            # Attempt to fetch sample rows (best-effort, may fail for some tables)\n",
    "            sample_info = \"\"\n",
    "            if query_tool:\n",
    "                try:\n",
    "                    # Get database type and use appropriate LIMIT syntax\n",
    "                    db_type = db_client.db_type.lower()\n",
    "                    \n",
    "                    if db_type == \"mssql\":\n",
    "                        sample_query = f\"SELECT TOP 3 * FROM {table_name}\"\n",
    "                    elif db_type in [\"oracle\"]:\n",
    "                        sample_query = f\"SELECT * FROM {table_name} WHERE ROWNUM <= 3\"\n",
    "                    else:  # postgres, mysql, sqlite\n",
    "                        sample_query = f\"SELECT * FROM {table_name} LIMIT 3\"\n",
    "                    \n",
    "                    sample_data = query_tool.invoke(sample_query)\n",
    "                    sample_info = f\"\\n\\nSample Data (first 3 rows):\\n{sample_data}\"\n",
    "                    print(\"Sample data fetched.\", sample_info)\n",
    "                except Exception as exc:\n",
    "                    sample_info = f\"\\n\\nSample data not available: {exc}\"\n",
    "            \n",
    "            # Build comprehensive document content\n",
    "            content = f\"\"\"Table: {table_name}\n",
    "\n",
    "    Schema Details:\n",
    "    {table_info}\n",
    "    {sample_info}\n",
    "\n",
    "    This table can be queried to answer questions about {table_name.replace('_', ' ')}.\n",
    "    \"\"\".strip()\n",
    "            \n",
    "            # Create Document object for vector indexing\n",
    "            doc = Document(\n",
    "                page_content=content,\n",
    "                metadata={\n",
    "                    \"table_name\": table_name,\n",
    "                    \"source\": \"database_schema\",\n",
    "                    \"type\": \"table_schema\",\n",
    "                    \"database_name\": db_client.database,\n",
    "                    \"db_type\": db_client.db_type,\n",
    "                }\n",
    "            )\n",
    "            schema_docs.append(doc)\n",
    "            success_count += 1\n",
    "            print(\"âœ“\")\n",
    "        \n",
    "        except Exception as exc:\n",
    "            # Track failures for reporting\n",
    "            error_msg = str(exc)[:150]\n",
    "            failed_tables.append((table_name, error_msg))\n",
    "            print(f\"âœ— ERROR: {error_msg}\")\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Step 5: Report Processing Results\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    if failed_tables:\n",
    "        print(f\"\\nâš ï¸ Failed Tables:\")\n",
    "        for table, error in failed_tables:\n",
    "            print(f\"   â€¢ {table}: {error}\")\n",
    "\n",
    "    print(f\"\\nâœ… Successfully created {len(schema_docs)} schema documents\")\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Step 6: Create and Persist Vector Store\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Convert documents to embeddings and store in Chroma DB\n",
    "    # This enables semantic similarity search over table schemas\n",
    "\n",
    "    embeddings = get_vector_embeddings()\n",
    "    collection_name = VECTOR_DB_SCHEMA_NAME + \"_\" + db_client.db_type + \"_\" + db_client.database\n",
    "    persist_directory = VECTOR_DB_SCHEMA_DIR + \"/\" + collection_name\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=schema_docs,\n",
    "        embedding=get_vector_embeddings(),\n",
    "        persist_directory=persist_directory,\n",
    "        collection_name=collection_name,\n",
    "    )\n",
    "\n",
    "    print(f\"âœ… Vector DB ready: {len(schema_docs)} documents indexed\")\n",
    "    print(f\"ğŸ’¾ Persisted to: {persist_directory}\")\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Final Summary Report\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"ğŸ“Š PROCESSING SUMMARY\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"âœ… Successful: {success_count}/{len(table_names)}\")\n",
    "    print(f\"âŒ Failed: {len(failed_tables)}/{len(table_names)}\")\n",
    "    print(f\"ğŸ“¦ Total Documents Indexed: {len(schema_docs)}\")\n",
    "    print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed02321",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ§¹ Step 2: Clean Up Vector Database (Optional Maintenance)\n",
    "\n",
    "**âš ï¸ Warning**: This cell **deletes** the entire vector database. Only run when needed!\n",
    "\n",
    "### When to Use:\n",
    "- **Corrupted Database**: Errors when loading vector store\n",
    "- **Schema Changes**: Major database restructuring\n",
    "- **Fresh Start**: Want to rebuild from scratch\n",
    "- **Troubleshooting**: Debugging vector store issues\n",
    "\n",
    "### After Running:\n",
    "- Go back to **Cell 1** to rebuild the vector database\n",
    "- Rebuilding will take a few minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150d602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 2: CLEAN UP VECTOR DATABASE (Optional Maintenance)\n",
    "# ============================================================================\n",
    "# Use this cell to remove corrupted or outdated vector database\n",
    "# âš ï¸ Run this ONLY when you need to rebuild from scratch\n",
    "\n",
    "import shutil\n",
    "from src.config.vector_config import VECTOR_DB_SCHEMA_DIR\n",
    "\n",
    "# Check if vector DB exists at expected location\n",
    "if os.path.exists(VECTOR_DB_SCHEMA_DIR):\n",
    "    print(f\"ğŸ—‘ï¸ Removing vector DB at: {VECTOR_DB_SCHEMA_DIR}\")\n",
    "    shutil.rmtree(VECTOR_DB_SCHEMA_DIR)\n",
    "    print(\"âœ… Vector DB removed successfully!\")\n",
    "    print(\"ğŸ’¡ Now run Cell 1 to rebuild it from scratch.\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ No vector DB found at the expected location.\")\n",
    "    print(f\"   Expected path: {VECTOR_DB_SCHEMA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97923f4e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“‚ Step 3: Load Existing Vector Database\n",
    "\n",
    "If you've already built the vector database in Cell 1, you can load it quickly without rebuilding.\n",
    "\n",
    "### âœ… Benefits:\n",
    "- **Fast Loading**: Loads in seconds vs. minutes to rebuild\n",
    "- **Preserves Embeddings**: Uses existing vector representations\n",
    "- **Normal Workflow**: Use this for day-to-day work\n",
    "\n",
    "### When to Use:\n",
    "- **Resuming Work**: Starting a new session\n",
    "- **Testing**: Running queries without rebuilding\n",
    "- **After Cell 1**: Once initial build is complete\n",
    "\n",
    "### ğŸ“ Note:\n",
    "If this cell shows \"No existing vector DB found\", run **Cell 1** first to create it.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a402a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 3: LOAD EXISTING VECTOR DATABASE\n",
    "# ============================================================================\n",
    "# Load previously created vector database instead of rebuilding from scratch\n",
    "# This is much faster and should be used for normal workflow\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from src.config.models import get_vector_embeddings\n",
    "from src.config.vector_config import VECTOR_DB_SCHEMA_DIR, VECTOR_DB_SCHEMA_NAME\n",
    "\n",
    "# Check if vector DB exists and has content\n",
    "if os.path.exists(VECTOR_DB_SCHEMA_DIR) and os.listdir(VECTOR_DB_SCHEMA_DIR):\n",
    "    print(\"â„¹ï¸ Loading existing vector DB...\")\n",
    "    \n",
    "    # Initialize Chroma with existing persisted data\n",
    "    vector_db = Chroma(\n",
    "        persist_directory=VECTOR_DB_SCHEMA_DIR,\n",
    "        collection_name=VECTOR_DB_SCHEMA_NAME,\n",
    "        embedding_function=get_vector_embeddings()\n",
    "    )\n",
    "    \n",
    "    # Get document count from collection\n",
    "    doc_count = vector_db._collection.count()\n",
    "    print(f\"âœ… Loaded {doc_count} documents from existing vector DB\")\n",
    "    print(f\"ğŸ“‚ Location: {VECTOR_DB_SCHEMA_DIR}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No existing vector DB found!\")\n",
    "    print(\"ğŸ’¡ Run Cell 1 first to create the vector database.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a7953c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”§ Step 4: Define Vector Search Tools\n",
    "\n",
    "Create custom LangChain tools that wrap vector store functionality for semantic table discovery.\n",
    "\n",
    "### ğŸ› ï¸ Tool 1: `semantic_table_search`\n",
    "**Purpose**: Find relevant tables using natural language  \n",
    "**Use Case**: \"Which tables contain customer information?\"  \n",
    "**Returns**: Table names with relevance scores\n",
    "\n",
    "### ğŸ› ï¸ Tool 2: `get_schema_by_semantic_search`\n",
    "**Purpose**: Get detailed schema for relevant tables  \n",
    "**Use Case**: Need structure info before writing SQL  \n",
    "**Returns**: CREATE TABLE statements and column definitions\n",
    "\n",
    "### ğŸ› ï¸ Tool 3: `list_relevant_tables_with_samples`\n",
    "**Purpose**: Get complete info including sample data  \n",
    "**Use Case**: Need to understand both structure and data patterns  \n",
    "**Returns**: Schema + first 3 rows of data\n",
    "\n",
    "### How It Works:\n",
    "1. Agent receives natural language question\n",
    "2. Converts question to vector embedding\n",
    "3. Performs similarity search against stored schemas\n",
    "4. Returns most relevant tables based on semantic meaning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa6e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: DEFINE VECTOR SEARCH TOOLS\n",
    "# ============================================================================\n",
    "# Create custom LangChain tools that wrap vector store functionality\n",
    "# These tools will be available to the agent for semantic table discovery\n",
    "\n",
    "from langchain.tools import tool\n",
    "from typing import List\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Tool 1: Semantic Table Search\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "@tool\n",
    "def semantic_table_search(query: str, k: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Find most relevant database tables using semantic search on schemas.\n",
    "    \n",
    "    This tool performs similarity search over vector embeddings of table schemas\n",
    "    to find tables that are semantically related to the query.\n",
    "    \n",
    "    Args:\n",
    "        query: Natural language description of what you're looking for\n",
    "               Example: \"sales customers orders\" or \"employee information\"\n",
    "        k: Number of top results to return (default: 3)\n",
    "    \n",
    "    Returns:\n",
    "        String listing the most relevant tables with their similarity scores\n",
    "        \n",
    "    Example:\n",
    "        semantic_table_search(\"product inventory\", k=3)\n",
    "        Returns top 3 tables related to products and inventory\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ” Semantic search: '{query}'\")\n",
    "    \n",
    "    # Perform similarity search with distance scores\n",
    "    # Chroma returns (document, distance) tuples\n",
    "    results_with_scores = vector_db.similarity_search_with_score(query, k=k)\n",
    "    \n",
    "    # Format results for agent consumption\n",
    "    output_lines = [f\"Top {k} tables for '{query}':\"]\n",
    "    for doc, score in results_with_scores:\n",
    "        table_name = doc.metadata.get('table_name', 'Unknown')\n",
    "        # Convert distance to similarity score (lower distance = higher similarity)\n",
    "        similarity = 1.0 / (1.0 + score) if score > 0 else 1.0\n",
    "        output_lines.append(f\"  â€¢ {table_name} (relevance: {similarity:.3f})\")\n",
    "    \n",
    "    return \"\\n\".join(output_lines)\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Tool 2: Schema Retrieval by Semantic Search\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "@tool\n",
    "def get_schema_by_semantic_search(query: str, k: int = 2) -> str:\n",
    "    \"\"\"\n",
    "    Get detailed schema information for semantically relevant tables.\n",
    "    \n",
    "    Returns full CREATE TABLE statements and column definitions for tables\n",
    "    that match the semantic query.\n",
    "    \n",
    "    Args:\n",
    "        query: Natural language description of what tables you need\n",
    "               Example: \"tables with customer contact information\"\n",
    "        k: Number of tables to retrieve (default: 2)\n",
    "    \n",
    "    Returns:\n",
    "        Detailed schema information for the most relevant tables including\n",
    "        column names, types, constraints, and relationships\n",
    "        \n",
    "    Example:\n",
    "        get_schema_by_semantic_search(\"employee departments\", k=2)\n",
    "        Returns schema details for Employee and Department tables\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ“‹ Semantic schema retrieval: '{query}'\")\n",
    "    \n",
    "    # Get relevant documents without scores\n",
    "    docs = vector_db.similarity_search(query, k=k)\n",
    "    \n",
    "    if not docs:\n",
    "        return \"No relevant tables found for your query.\"\n",
    "    \n",
    "    # Combine schema information from multiple tables\n",
    "    schema_parts = []\n",
    "    for i, doc in enumerate(docs, 1):\n",
    "        table_name = doc.metadata.get('table_name', 'Unknown')\n",
    "        schema_parts.append(f\"--- Table {i}: {table_name} ---\")\n",
    "        schema_parts.append(doc.page_content)\n",
    "        schema_parts.append(\"\")  # Blank line separator\n",
    "    \n",
    "    return \"\\n\".join(schema_parts)\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Tool 3: Complete Table Information with Samples\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "@tool\n",
    "def list_relevant_tables_with_samples(query: str, k: int = 2) -> str:\n",
    "    \"\"\"\n",
    "    Get table names, schemas, AND sample data for relevant tables.\n",
    "    \n",
    "    This is the most comprehensive tool - it returns everything you need\n",
    "    to understand a table: structure, column types, and actual data examples.\n",
    "    \n",
    "    Args:\n",
    "        query: What you're looking for\n",
    "               Example: \"order history\" or \"product pricing\"\n",
    "        k: Number of tables to retrieve (default: 2)\n",
    "    \n",
    "    Returns:\n",
    "        Complete information including:\n",
    "        - Table name and metadata\n",
    "        - Full schema (columns, types, constraints)\n",
    "        - Sample rows (first 3 rows if available)\n",
    "        \n",
    "    Example:\n",
    "        list_relevant_tables_with_samples(\"sales data\", k=2)\n",
    "        Returns schema + sample data for top 2 sales-related tables\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ“Š Getting tables with samples: '{query}'\")\n",
    "    \n",
    "    # Retrieve semantically similar documents\n",
    "    docs = vector_db.similarity_search(query, k=k)\n",
    "    \n",
    "    if not docs:\n",
    "        return \"No relevant tables found for your query.\"\n",
    "    \n",
    "    # Format comprehensive output\n",
    "    result_parts = []\n",
    "    for doc in docs:\n",
    "        table_name = doc.metadata.get('table_name', 'Unknown')\n",
    "        result_parts.append(f\"\\n{'='*60}\")\n",
    "        result_parts.append(f\"Table: {table_name}\")\n",
    "        result_parts.append(f\"{'='*60}\")\n",
    "        result_parts.append(doc.page_content)  # Includes schema + samples\n",
    "    \n",
    "    return \"\\n\".join(result_parts)\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Register Tools Collection\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "VECTOR_TOOLS = [\n",
    "    semantic_table_search,\n",
    "    get_schema_by_semantic_search,\n",
    "    list_relevant_tables_with_samples\n",
    "]\n",
    "\n",
    "print(f\"âœ… Created {len(VECTOR_TOOLS)} vector search tools:\")\n",
    "for tool in VECTOR_TOOLS:\n",
    "    print(f\"   â€¢ {tool.name}: {tool.description.split('.')[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15006fc1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ§ª Step 6: Test Vector Search Tools\n",
    "\n",
    "Before using the full agent, let's test each vector search tool individually to verify they work correctly.\n",
    "\n",
    "### Test Plan:\n",
    "1. âœ… Search for sales-related tables\n",
    "2. âœ… Search for HR/employee tables\n",
    "3. âœ… Get detailed schema for products\n",
    "4. âœ… Get complete info with samples\n",
    "\n",
    "### What to Look For:\n",
    "- **Relevance Scores**: Should be >0.6 for good matches\n",
    "- **Table Names**: Should make semantic sense for the query\n",
    "- **Schema Content**: Should include column definitions\n",
    "- **Sample Data**: Should show actual values (if available)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6c6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 6: TEST VECTOR SEARCH TOOLS\n",
    "# ============================================================================\n",
    "# Verify each tool works correctly before using in agent\n",
    "\n",
    "print(\"ğŸ§ª Testing Vector Search Tools\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Test 1: Search for Sales Tables\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n1. ğŸ” Search for sales-related tables:\")\n",
    "result1 = semantic_table_search.invoke({\"query\": \"sales customers orders\", \"k\": 3})\n",
    "print(result1)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Test 2: Search for Employee/HR Tables\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n2. ğŸ” Search for employee/HR tables:\")\n",
    "result2 = semantic_table_search.invoke({\"query\": \"employee department salary\", \"k\": 3})\n",
    "print(result2)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Test 3: Get Schema for Product Tables\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n3. ğŸ“‹ Get schema for product-related tables:\")\n",
    "result3 = get_schema_by_semantic_search.invoke({\"query\": \"products inventory\", \"k\": 2})\n",
    "# Truncate output if too long\n",
    "print(result3[:500] + \"...\" if len(result3) > 500 else result3)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Test 4: Get Complete Information with Samples\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"\\n4. ğŸ“Š Get tables with sample data:\")\n",
    "result4 = list_relevant_tables_with_samples.invoke({\"query\": \"customer information\", \"k\": 1})\n",
    "# Truncate output if too long\n",
    "print(result4[:800] + \"...\" if len(result4) > 800 else result4)\n",
    "\n",
    "print(\"\\nâœ… All vector search tools tested successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceee127",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ”¬ Step 8: Inspect Vector Store Contents\n",
    "\n",
    "Debug and understand what's stored in the vector database.\n",
    "\n",
    "### What to Check:\n",
    "- **Total Document Count**: Number of tables indexed\n",
    "- **Sample Documents**: Preview of stored content\n",
    "- **Metadata Structure**: How tables are organized\n",
    "- **Embedding Model**: Which model is used\n",
    "- **Storage Location**: Where files are persisted\n",
    "\n",
    "### Use This For:\n",
    "- âœ… Verify vector store was built correctly\n",
    "- âœ… Debug search issues\n",
    "- âœ… Understand document structure\n",
    "- âœ… Check for missing tables\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dac724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: INSPECT VECTOR STORE CONTENTS\n",
    "# ============================================================================\n",
    "# Debug tool to examine what's actually stored in the vector database\n",
    "\n",
    "print(\"ğŸ” Vector Store Contents Inspection\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Step 1: Get Collection Statistics\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "collection = vector_db._collection\n",
    "total_docs = collection.count()\n",
    "print(f\"ğŸ“Š Total documents in vector store: {total_docs}\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Step 2: Retrieve Sample Documents\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Use generic query to get a representative sample\n",
    "max_display = 5\n",
    "all_docs = vector_db.similarity_search(\"database table\", k=min(total_docs, 10))\n",
    "\n",
    "print(f\"\\nğŸ“š Showing first {min(len(all_docs), max_display)} documents:\\n\")\n",
    "\n",
    "for i, doc in enumerate(all_docs[:max_display], 1):\n",
    "    print(f\"{'â”€' * 70}\")\n",
    "    print(f\"Document {i}:\")\n",
    "    print(f\"{'â”€' * 70}\")\n",
    "    print(f\"Table: {doc.metadata.get('table_name', 'N/A')}\")\n",
    "    print(f\"Type: {doc.metadata.get('type', 'N/A')}\")\n",
    "    print(f\"Source: {doc.metadata.get('source', 'N/A')}\")\n",
    "    print(f\"\\nContent Preview:\")\n",
    "    # Show first 400 characters of document content\n",
    "    content_preview = doc.page_content[:400] + \"...\" if len(doc.page_content) > 400 else doc.page_content\n",
    "    print(content_preview)\n",
    "    print()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Step 3: Display Summary Statistics\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(f\"{'='*70}\")\n",
    "print(\"ğŸ“ˆ Vector Store Statistics:\")\n",
    "print(f\"   â€¢ Collection Name: {VECTOR_DB_SCHEMA_NAME}\")\n",
    "print(f\"   â€¢ Storage Location: {VECTOR_DB_SCHEMA_DIR}\")\n",
    "print(f\"   â€¢ Total Documents: {total_docs}\")\n",
    "print(f\"   â€¢ Embedding Model: {get_vector_embeddings().model}\")\n",
    "print(f\"   â€¢ Documents Displayed: {min(len(all_docs), max_display)}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73a9038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DIAGNOSTIC: Check Vector Store Status\n",
    "# ============================================================================\n",
    "import os\n",
    "from src.config.vector_config import VECTOR_DB_SCHEMA_DIR, VECTOR_DB_SCHEMA_NAME\n",
    "\n",
    "print(\"ğŸ” Vector Store Diagnostic\\n\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check 1: Does the directory exist?\n",
    "print(f\"\\n1ï¸âƒ£ Checking directory: {VECTOR_DB_SCHEMA_DIR}\")\n",
    "abs_path = os.path.abspath(VECTOR_DB_SCHEMA_DIR)\n",
    "print(f\"   Absolute path: {abs_path}\")\n",
    "print(f\"   Exists: {os.path.exists(abs_path)}\")\n",
    "\n",
    "if os.path.exists(abs_path):\n",
    "    files = os.listdir(abs_path)\n",
    "    print(f\"   Files: {files}\")\n",
    "else:\n",
    "    print(\"   âš ï¸ Directory does not exist!\")\n",
    "    print(\"   ğŸ’¡ Solution: Run notebook/5.1-vector-agent.ipynb Cell 1 to build vector DB\")\n",
    "\n",
    "# Check 2: Try to load the vector store\n",
    "print(f\"\\n2ï¸âƒ£ Attempting to load vector store...\")\n",
    "try:\n",
    "    from langchain_community.vectorstores import Chroma\n",
    "    from src.config.models import get_vector_embeddings\n",
    "    \n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=VECTOR_DB_SCHEMA_DIR,\n",
    "        collection_name=VECTOR_DB_SCHEMA_NAME,\n",
    "        embedding_function=get_vector_embeddings()\n",
    "    )\n",
    "    \n",
    "    # Check document count\n",
    "    doc_count = vectorstore._collection.count()\n",
    "    print(f\"   âœ… Vector store loaded successfully!\")\n",
    "    print(f\"   ğŸ“Š Total documents: {doc_count}\")\n",
    "    \n",
    "    if doc_count == 0:\n",
    "        print(\"   âš ï¸ WARNING: Vector store is EMPTY!\")\n",
    "        print(\"   ğŸ’¡ Solution: Run notebook/5.1-vector-agent.ipynb Cell 1 to populate it\")\n",
    "    \n",
    "    # Check 3: Try a sample search\n",
    "    print(f\"\\n3ï¸âƒ£ Testing sample search...\")\n",
    "    results = vectorstore.similarity_search(\"employee Department details\", k=2)\n",
    "    print(f\"   Found {len(results)} results\")\n",
    "    \n",
    "    if results:\n",
    "        print(f\"   Sample result:\")\n",
    "        sample = results[0]\n",
    "        print(f\"     â€¢ Table: {sample.metadata.get('table_name', 'Unknown')}\")\n",
    "        print(f\"     â€¢ Content preview: {sample.page_content}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"   âŒ Error loading vector store: {e}\")\n",
    "    import traceback\n",
    "    print(\"\\n   Full traceback:\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"\\nğŸ’¡ If vector store is empty or missing:\")\n",
    "print(\"   1. Open notebook/5.1-vector-agent.ipynb\")\n",
    "print(\"   2. Run Cell 1 (Build & Index Vector Database)\")\n",
    "print(\"   3. Wait for it to complete (~2-5 minutes)\")\n",
    "print(\"   4. Come back and re-run this notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710914ca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ§¬ Step 9: Test Different Embedding Models\n",
    "\n",
    "Test and compare different embedding models for vector search.\n",
    "\n",
    "### What Are Embeddings?\n",
    "Vector representations of text that capture semantic meaning. Similar text = similar vectors.\n",
    "\n",
    "### Available Models:\n",
    "- **OpenAI**: `text-embedding-3-small`, `text-embedding-3-large`, `text-embedding-ada-002`\n",
    "- **HuggingFace**: `all-MiniLM-L6-v2`, `all-mpnet-base-v2`\n",
    "- **Sentence Transformers**: Various open-source models\n",
    "\n",
    "### What This Tests:\n",
    "- Current embedding model configuration\n",
    "- Model loading and initialization\n",
    "- Sample embedding generation\n",
    "- Vector dimensionality\n",
    "\n",
    "### ğŸ’¡ Why This Matters:\n",
    "- Different models have different dimensions (384, 768, 1536, 3072)\n",
    "- Quality affects search accuracy\n",
    "- Speed affects query latency\n",
    "- Cost affects production budget\n",
    "\n",
    "**Note**: Changing embedding models requires **rebuilding the vector store**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef5eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test switching embedding models\n",
    "from src.config.models import get_vector_embeddings\n",
    "from src.config.models import default_embedding_model\n",
    "\n",
    "print(\"Current embedding model:\")\n",
    "print(f\"  Provider: {default_embedding_model['provider']}\")\n",
    "print(f\"  Model: {default_embedding_model['model']}\")\n",
    "\n",
    "# Get embeddings instance\n",
    "embeddings = get_vector_embeddings()\n",
    "print(f\"\\nâœ… Embeddings loaded: {type(embeddings).__name__}\")\n",
    "\n",
    "# Test embedding a sample text\n",
    "sample_text = \"customer sales data\"\n",
    "embedding_vector = embeddings.embed_query(sample_text)\n",
    "print(f\"\\nâœ… Sample embedding dimension: {len(embedding_vector)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
