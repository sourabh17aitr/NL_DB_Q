{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3688ec0",
   "metadata": {},
   "source": [
    "# NL2SQL Agent Workflow - Usage Guide\n",
    "\n",
    "This notebook demonstrates how to use the agent_workflow implementation for converting natural language queries to SQL.\n",
    "\n",
    "## Features\n",
    "- Simple API for querying databases\n",
    "- Automatic retry and error recovery\n",
    "- Optional monitoring and metrics\n",
    "- Support for multiple LLM providers\n",
    "- Production-ready implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d6d60be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "# Add project root to path\n",
    "notebook_dir = os.getcwd()\n",
    "project_root = os.path.dirname(notebook_dir)\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d9d6d1",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "The workflow reads configuration from environment variables. Make sure your `.env` file has:\n",
    "\n",
    "```bash\n",
    "# LLM Configuration\n",
    "LLM_PROVIDER=ollama\n",
    "LLM_MODEL=llama3.1:8b\n",
    "LLM_TEMPERATURE=0\n",
    "\n",
    "# Workflow Settings\n",
    "MAX_RETRIES=3\n",
    "VECTOR_SEARCH_K=5\n",
    "\n",
    "# Monitoring\n",
    "ENABLE_MONITORING=true\n",
    "EXPORT_METRICS=false\n",
    "METRICS_FILE=nl2sql_metrics.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21ad3bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\\.venv\\lib\\site-packages\\google\\api_core\\_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.11) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\\.venv\\lib\\site-packages\\langchain_community\\utilities\\sql_database.py:159: SAWarning: Did not recognize type 'sysname' of column 'DatabaseUser'\n",
      "  self._metadata.reflect(\n",
      "c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\\.venv\\lib\\site-packages\\langchain_community\\utilities\\sql_database.py:159: SAWarning: Did not recognize type 'sysname' of column 'Event'\n",
      "  self._metadata.reflect(\n",
      "c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\\.venv\\lib\\site-packages\\langchain_community\\utilities\\sql_database.py:159: SAWarning: Did not recognize type 'sysname' of column 'Schema'\n",
      "  self._metadata.reflect(\n",
      "c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\\.venv\\lib\\site-packages\\langchain_community\\utilities\\sql_database.py:159: SAWarning: Did not recognize type 'sysname' of column 'Object'\n",
      "  self._metadata.reflect(\n",
      "c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\\.venv\\lib\\site-packages\\langchain_community\\utilities\\sql_database.py:159: SAWarning: Did not recognize type 'sysname' of column 'UserName'\n",
      "  self._metadata.reflect(\n",
      "INFO: Connected to database: mssql\n",
      "INFO: Using LLM: ollama:llama3.1:8b\n",
      "INFO: Monitoring enabled: True\n",
      "INFO: NL2SQL workflow compiled successfully\n",
      "INFO: Workflow nodes: parallel_schema_retrieval â†’ query_generation â†’ query_validation â†’ query_execution â†’ result_formatting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Configuration:\n",
      "  LLM Provider: ollama\n",
      "  LLM Model: llama3.1:8b\n",
      "  Max Retries: 3\n",
      "  Monitoring Enabled: True\n",
      "  Vector Search K: 5\n"
     ]
    }
   ],
   "source": [
    "# Import the main function\n",
    "from src.agent_workflow import run_nl2sql_query, WorkflowConfig\n",
    "\n",
    "# Display current configuration\n",
    "print(\"Current Configuration:\")\n",
    "print(f\"  LLM Provider: {WorkflowConfig.LLM_PROVIDER}\")\n",
    "print(f\"  LLM Model: {WorkflowConfig.LLM_MODEL}\")\n",
    "print(f\"  Max Retries: {WorkflowConfig.MAX_RETRIES}\")\n",
    "print(f\"  Monitoring Enabled: {WorkflowConfig.ENABLE_MONITORING}\")\n",
    "print(f\"  Vector Search K: {WorkflowConfig.VECTOR_SEARCH_K}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fd36aa",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "The simplest way to use the workflow is with the `run_nl2sql_query()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5d8428d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Pipeline started at 03:02:11\n",
      "INFO: Executing query: How many customers do we have?\n",
      "INFO: Parallel Schema Retrieval: Starting vector search & database lookup...\n",
      "INFO: [Vector] Searching for relevant tables...\n",
      "INFO: [Database] Fetching available tables...\n",
      "INFO: Found 71 tables\n",
      "INFO: [Database] Found 71 tables (schema: HumanResources)\n",
      "c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\\src\\agents\\vector_retriver_tools.py:10: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
      "  return Chroma(\n",
      "INFO: Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "WARNING: [Vector] No results found\n",
      "INFO: Parallel execution completed\n",
      "WARNING: No vector results, using database tables with LLM filtering\n",
      "INFO: Using LLM to filter relevant tables from 71 available\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: Fetching schema for 1 table(s)...\n",
      "INFO: Retrieved schema for: Sales.Customer\n",
      "INFO: Retrieved schema for 1 tables\n",
      "INFO: Schema detected: HumanResources\n",
      "INFO: Final table selection: Sales.Customer\n",
      "INFO: Query Generation: Creating SQL query...\n",
      "INFO: Using schema-qualified names: HumanResources.tablename\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: Generated SQL:\n",
      "SELECT COUNT(CustomerID) FROM Sales.Customer\n",
      "INFO: Query Validation: Checking query safety...\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: Query syntax validated by toolkit\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: Validation Passed: Query is valid\n",
      "INFO: Query Execution: Running SQL query...\n",
      "INFO: Query executed successfully\n",
      "INFO: Result Formatting: Creating natural language response...\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: Response generated\n",
      "INFO: Completed in 39.60s (Success)\n",
      "INFO: \n",
      "================================================================================\n",
      "INFO: PRODUCTION MONITORING SUMMARY\n",
      "INFO: ================================================================================\n",
      "INFO: \n",
      "PIPELINE METRICS:\n",
      "INFO:    Total Duration: 39.60s\n",
      "INFO:    Status: Success\n",
      "INFO:    Total Steps: 5\n",
      "INFO:    Retries: 0\n",
      "INFO:    Validation Failures: 0\n",
      "INFO:    Execution Failures: 0\n",
      "INFO: \n",
      "NODE EXECUTION METRICS:\n",
      "INFO:    parallel_schema_retrieval: 1 exec, 9.552s total, 9.552s avg, 0 errors\n",
      "INFO:    query_generation: 1 exec, 1.332s total, 1.332s avg, 0 errors\n",
      "INFO:    query_validation: 1 exec, 27.489s total, 27.489s avg, 0 errors\n",
      "INFO:    query_execution: 1 exec, 0.008s total, 0.008s avg, 0 errors\n",
      "INFO:    result_formatting: 1 exec, 1.209s total, 1.209s avg, 0 errors\n",
      "INFO: \n",
      "LLM USAGE METRICS:\n",
      "INFO:    Total Calls: 0\n",
      "INFO:    Token Usage: N/A (Ollama local model)\n",
      "INFO: \n",
      "EXECUTION TIMELINE:\n",
      "INFO:    1. parallel_schema_retrieval: 9.552s\n",
      "INFO:    2. query_generation: 1.332s\n",
      "INFO:    3. query_validation: 27.489s\n",
      "INFO:    4. query_execution: 0.008s\n",
      "INFO:    5. result_formatting: 1.209s\n",
      "INFO: ================================================================================\n",
      "INFO: Query execution completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL RESPONSE:\n",
      "================================================================================\n",
      "We have **19,820** customers.\n"
     ]
    }
   ],
   "source": [
    "# Simple query example\n",
    "query = \"How many customers do we have?\"\n",
    "\n",
    "result = run_nl2sql_query(query)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\" * 80)\n",
    "print(result[\"final_response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c81897",
   "metadata": {},
   "source": [
    "## Accessing Query Details\n",
    "\n",
    "The result contains comprehensive information about the query execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c2680c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QUERY DETAILS:\n",
      "================================================================================\n",
      "\n",
      "Generated SQL Query:\n",
      "--------------------------------------------------------------------------------\n",
      "SELECT COUNT(CustomerID) FROM Sales.Customer\n",
      "\n",
      "Relevant Tables Used:\n",
      "--------------------------------------------------------------------------------\n",
      "Sales.Customer\n",
      "\n",
      "Retry Count:\n",
      "--------------------------------------------------------------------------------\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Access different parts of the result\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"QUERY DETAILS:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nGenerated SQL Query:\")\n",
    "print(\"-\" * 80)\n",
    "print(result.get(\"generated_query\", \"N/A\"))\n",
    "\n",
    "print(\"\\nRelevant Tables Used:\")\n",
    "print(\"-\" * 80)\n",
    "print(\", \".join(result.get(\"relevant_tables\", [])))\n",
    "\n",
    "print(\"\\nRetry Count:\")\n",
    "print(\"-\" * 80)\n",
    "print(result.get(\"retry_count\", 0))\n",
    "\n",
    "if result.get(\"execution_error\"):\n",
    "    print(\"\\nExecution Error:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(result[\"execution_error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f93ff2",
   "metadata": {},
   "source": [
    "## Example 1: Simple Aggregation Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6153d9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Pipeline started at 03:03:10\n",
      "INFO: Executing query: What is the total number of orders placed?\n",
      "INFO: Parallel Schema Retrieval: Starting vector search & database lookup...\n",
      "INFO: [Vector] Searching for relevant tables...\n",
      "INFO: [Database] Fetching available tables...\n",
      "INFO: Found 71 tables\n",
      "INFO: [Database] Found 71 tables (schema: HumanResources)\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "WARNING: [Vector] No results found\n",
      "INFO: Parallel execution completed\n",
      "WARNING: No vector results, using database tables with LLM filtering\n",
      "INFO: Using LLM to filter relevant tables from 71 available\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: Fetching schema for 2 table(s)...\n",
      "c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\\src\\agents\\tools.py:122: SAWarning: Did not recognize type 'Flag' of column 'OnlineOrderFlag'\n",
      "  columns = self.inspector.get_columns(table, schema=schema_name)\n",
      "c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\\src\\agents\\tools.py:122: SAWarning: Did not recognize type 'OrderNumber' of column 'PurchaseOrderNumber'\n",
      "  columns = self.inspector.get_columns(table, schema=schema_name)\n",
      "c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\\src\\agents\\tools.py:122: SAWarning: Did not recognize type 'AccountNumber' of column 'AccountNumber'\n",
      "  columns = self.inspector.get_columns(table, schema=schema_name)\n",
      "INFO: Retrieved schema for: Sales.SalesOrderHeader\n",
      "INFO: Retrieved schema for: Sales.SalesOrderDetail\n",
      "INFO: Retrieved schema for 2 tables\n",
      "INFO: Schema detected: HumanResources\n",
      "INFO: Final table selection: Sales.SalesOrderHeader, Sales.SalesOrderDetail\n",
      "INFO: Query Generation: Creating SQL query...\n",
      "INFO: Using schema-qualified names: HumanResources.tablename\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: Generated SQL:\n",
      "SELECT COUNT(DISTINCT SalesOrderID) FROM Sales.SalesOrderHeader\n",
      "INFO: Query Validation: Checking query safety...\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: Query syntax validated by toolkit\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: Validation Passed: Query is valid\n",
      "INFO: Query Execution: Running SQL query...\n",
      "INFO: Query executed successfully\n",
      "INFO: Result Formatting: Creating natural language response...\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: Response generated\n",
      "INFO: Completed in 48.82s (Success)\n",
      "INFO: \n",
      "================================================================================\n",
      "INFO: PRODUCTION MONITORING SUMMARY\n",
      "INFO: ================================================================================\n",
      "INFO: \n",
      "PIPELINE METRICS:\n",
      "INFO:    Total Duration: 48.82s\n",
      "INFO:    Status: Success\n",
      "INFO:    Total Steps: 5\n",
      "INFO:    Retries: 0\n",
      "INFO:    Validation Failures: 0\n",
      "INFO:    Execution Failures: 0\n",
      "INFO: \n",
      "NODE EXECUTION METRICS:\n",
      "INFO:    parallel_schema_retrieval: 1 exec, 3.467s total, 3.467s avg, 0 errors\n",
      "INFO:    query_generation: 1 exec, 2.910s total, 2.910s avg, 0 errors\n",
      "INFO:    query_validation: 1 exec, 41.004s total, 41.004s avg, 0 errors\n",
      "INFO:    query_execution: 1 exec, 0.024s total, 0.024s avg, 0 errors\n",
      "INFO:    result_formatting: 1 exec, 1.412s total, 1.412s avg, 0 errors\n",
      "INFO: \n",
      "LLM USAGE METRICS:\n",
      "INFO:    Total Calls: 0\n",
      "INFO:    Token Usage: N/A (Ollama local model)\n",
      "INFO: \n",
      "EXECUTION TIMELINE:\n",
      "INFO:    1. parallel_schema_retrieval: 3.467s\n",
      "INFO:    2. query_generation: 2.910s\n",
      "INFO:    3. query_validation: 41.004s\n",
      "INFO:    4. query_execution: 0.024s\n",
      "INFO:    5. result_formatting: 1.412s\n",
      "INFO: ================================================================================\n",
      "INFO: Query execution completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User Question:\n",
      "  What is the total number of orders placed?\n",
      "\n",
      "Generated SQL:\n",
      "  SELECT COUNT(DISTINCT SalesOrderID) FROM Sales.SalesOrderHeader\n",
      "\n",
      "Final Answer:\n",
      "  There are **31,465** unique orders placed.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the total number of orders placed?\"\n",
    "\n",
    "result = run_nl2sql_query(query)\n",
    "\n",
    "print(\"\\nUser Question:\")\n",
    "print(f\"  {query}\")\n",
    "\n",
    "print(\"\\nGenerated SQL:\")\n",
    "print(f\"  {result['generated_query']}\")\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(f\"  {result['final_response']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9af3c2",
   "metadata": {},
   "source": [
    "## Example 2: Join Query with Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a78cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"List the top 5 products by sales amount\"\n",
    "\n",
    "result = run_nl2sql_query(query)\n",
    "\n",
    "print(\"\\nUser Question:\")\n",
    "print(f\"  {query}\")\n",
    "\n",
    "print(\"\\nGenerated SQL:\")\n",
    "print(f\"  {result['generated_query']}\")\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(f\"  {result['final_response']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea871ddb",
   "metadata": {},
   "source": [
    "## Example 3: Complex Query with Multiple Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9374588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Show me the departments with more than 10 employees\"\n",
    "\n",
    "result = run_nl2sql_query(query)\n",
    "\n",
    "print(\"\\nUser Question:\")\n",
    "print(f\"  {query}\")\n",
    "\n",
    "print(\"\\nGenerated SQL:\")\n",
    "print(f\"  {result['generated_query']}\")\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(f\"  {result['final_response']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a35aae",
   "metadata": {},
   "source": [
    "## Example 4: Time-Based Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cb15fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What were the total sales in the last month?\"\n",
    "\n",
    "result = run_nl2sql_query(query)\n",
    "\n",
    "print(\"\\nUser Question:\")\n",
    "print(f\"  {query}\")\n",
    "\n",
    "print(\"\\nGenerated SQL:\")\n",
    "print(f\"  {result['generated_query']}\")\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(f\"  {result['final_response']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44b131e",
   "metadata": {},
   "source": [
    "## Custom Retry Configuration\n",
    "\n",
    "You can override the default max retries for specific queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b869654",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Show me the top 10 customers by purchase frequency\"\n",
    "\n",
    "# Use custom retry limit\n",
    "result = run_nl2sql_query(query, max_retries=5)\n",
    "\n",
    "print(\"\\nQuery with custom retry limit (5):\")\n",
    "print(f\"  {query}\")\n",
    "\n",
    "print(f\"\\nRetries used: {result.get('retry_count', 0)}\")\n",
    "print(f\"\\nFinal Answer:\\n  {result['final_response']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd8911",
   "metadata": {},
   "source": [
    "## Error Handling\n",
    "\n",
    "The workflow handles errors gracefully and provides informative messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a6a6684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Pipeline started at 03:04:15\n",
      "INFO: Executing query: Show me all the unicorns in the database\n",
      "INFO: Parallel Schema Retrieval: Starting vector search & database lookup...\n",
      "INFO: [Vector] Searching for relevant tables...\n",
      "INFO: [Database] Fetching available tables...\n",
      "INFO: Found 71 tables\n",
      "INFO: [Database] Found 71 tables (schema: HumanResources)\n",
      "INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "WARNING: [Vector] No results found\n",
      "INFO: Parallel execution completed\n",
      "WARNING: No vector results, using database tables with LLM filtering\n",
      "INFO: Using LLM to filter relevant tables from 71 available\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: Fetching schema for 2 table(s)...\n",
      "c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\\src\\agents\\tools.py:122: SAWarning: Did not recognize type 'hierarchyid' of column 'OrganizationNode'\n",
      "  columns = self.inspector.get_columns(table, schema=schema_name)\n",
      "c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\\src\\agents\\tools.py:122: SAWarning: Did not recognize type 'Flag' of column 'SalariedFlag'\n",
      "  columns = self.inspector.get_columns(table, schema=schema_name)\n",
      "c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\\src\\agents\\tools.py:122: SAWarning: Did not recognize type 'Flag' of column 'CurrentFlag'\n",
      "  columns = self.inspector.get_columns(table, schema=schema_name)\n",
      "INFO: Retrieved schema for: HumanResources.Employee\n",
      "c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\\src\\agents\\tools.py:122: SAWarning: Did not recognize type 'NameStyle' of column 'NameStyle'\n",
      "  columns = self.inspector.get_columns(table, schema=schema_name)\n",
      "c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\\src\\agents\\tools.py:122: SAWarning: Did not recognize type 'Name' of column 'FirstName'\n",
      "  columns = self.inspector.get_columns(table, schema=schema_name)\n",
      "c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\\src\\agents\\tools.py:122: SAWarning: Did not recognize type 'Name' of column 'MiddleName'\n",
      "  columns = self.inspector.get_columns(table, schema=schema_name)\n",
      "c:\\Users\\sourabh.gupta\\Documents\\Workspace\\Projects\\nldbq-langchain\\src\\agents\\tools.py:122: SAWarning: Did not recognize type 'Name' of column 'LastName'\n",
      "  columns = self.inspector.get_columns(table, schema=schema_name)\n",
      "INFO: Retrieved schema for: Person.Person\n",
      "INFO: Retrieved schema for 2 tables\n",
      "INFO: Schema detected: HumanResources\n",
      "INFO: Final table selection: HumanResources.Employee, Person.Person\n",
      "INFO: Query Generation: Creating SQL query...\n",
      "INFO: Using schema-qualified names: HumanResources.tablename\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: Generated SQL:\n",
      "SELECT TOP 100 BusinessEntityID, FirstName, LastName \n",
      "FROM Person.Person \n",
      "WHERE PersonType = 'IN'\n",
      "INFO: Query Validation: Checking query safety...\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: Query syntax validated by toolkit\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: Validation Passed: Query is valid\n",
      "INFO: Query Execution: Running SQL query...\n",
      "INFO: Query executed successfully\n",
      "INFO: Result Formatting: Creating natural language response...\n",
      "INFO: HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "INFO: Response generated\n",
      "INFO: Completed in 34.74s (Success)\n",
      "INFO: \n",
      "================================================================================\n",
      "INFO: PRODUCTION MONITORING SUMMARY\n",
      "INFO: ================================================================================\n",
      "INFO: \n",
      "PIPELINE METRICS:\n",
      "INFO:    Total Duration: 34.74s\n",
      "INFO:    Status: Success\n",
      "INFO:    Total Steps: 5\n",
      "INFO:    Retries: 0\n",
      "INFO:    Validation Failures: 0\n",
      "INFO:    Execution Failures: 0\n",
      "INFO: \n",
      "NODE EXECUTION METRICS:\n",
      "INFO:    parallel_schema_retrieval: 1 exec, 2.715s total, 2.715s avg, 0 errors\n",
      "INFO:    query_generation: 1 exec, 3.368s total, 3.368s avg, 0 errors\n",
      "INFO:    query_validation: 1 exec, 22.149s total, 22.149s avg, 0 errors\n",
      "INFO:    query_execution: 1 exec, 0.061s total, 0.061s avg, 0 errors\n",
      "INFO:    result_formatting: 1 exec, 6.442s total, 6.442s avg, 0 errors\n",
      "INFO: \n",
      "LLM USAGE METRICS:\n",
      "INFO:    Total Calls: 0\n",
      "INFO:    Token Usage: N/A (Ollama local model)\n",
      "INFO: \n",
      "EXECUTION TIMELINE:\n",
      "INFO:    1. parallel_schema_retrieval: 2.715s\n",
      "INFO:    2. query_generation: 3.368s\n",
      "INFO:    3. query_validation: 22.149s\n",
      "INFO:    4. query_execution: 0.061s\n",
      "INFO:    5. result_formatting: 6.442s\n",
      "INFO: ================================================================================\n",
      "INFO: Query execution completed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Response:\n",
      "  There are **no unicorns** in the database. The query returned 43 records of people with different names and characteristics, but none of them match the mythical creature known as a unicorn.\n"
     ]
    }
   ],
   "source": [
    "# Try a query that might fail\n",
    "query = \"Show me all the unicorns in the database\"\n",
    "\n",
    "try:\n",
    "    result = run_nl2sql_query(query)\n",
    "    \n",
    "    if result.get(\"execution_error\") or result.get(\"validation_error\"):\n",
    "        print(\"\\nQuery had issues:\")\n",
    "        print(f\"  Validation Error: {result.get('validation_error', 'None')}\")\n",
    "        print(f\"  Execution Error: {result.get('execution_error', 'None')}\")\n",
    "    \n",
    "    print(f\"\\nFinal Response:\\n  {result['final_response']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nException occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec1594d",
   "metadata": {},
   "source": [
    "## Monitoring and Metrics\n",
    "\n",
    "When monitoring is enabled, you can access detailed performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "653d1b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitoring is enabled!\n",
      "\n",
      "To see detailed metrics, check the logs above.\n",
      "The workflow automatically prints a summary after each query.\n",
      "\n",
      "================================================================================\n",
      "QUICK METRICS SUMMARY:\n",
      "================================================================================\n",
      "\n",
      "Pipeline Duration: 34.74s\n",
      "Success: True\n",
      "Total Steps: 5\n",
      "Retries: 0\n",
      "\n",
      "Node Execution Times:\n",
      "  parallel_schema_retrieval: 2.715s avg (1 exec)\n",
      "  query_generation: 3.368s avg (1 exec)\n",
      "  query_validation: 22.149s avg (1 exec)\n",
      "  query_execution: 0.061s avg (1 exec)\n",
      "  result_formatting: 6.442s avg (1 exec)\n",
      "\n",
      "LLM Calls: 0\n"
     ]
    }
   ],
   "source": [
    "# Check if monitoring is enabled\n",
    "if WorkflowConfig.ENABLE_MONITORING:\n",
    "    from src.agent_workflow.workflow import monitor\n",
    "    \n",
    "    print(\"Monitoring is enabled!\")\n",
    "    print(\"\\nTo see detailed metrics, check the logs above.\")\n",
    "    print(\"The workflow automatically prints a summary after each query.\")\n",
    "    \n",
    "    # Get the last metrics summary\n",
    "    summary = monitor.get_summary()\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"QUICK METRICS SUMMARY:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(f\"\\nPipeline Duration: {summary['pipeline']['total_duration']:.2f}s\")\n",
    "    print(f\"Success: {summary['pipeline']['success']}\")\n",
    "    print(f\"Total Steps: {summary['pipeline']['total_steps']}\")\n",
    "    print(f\"Retries: {summary['pipeline']['retries']}\")\n",
    "    \n",
    "    print(\"\\nNode Execution Times:\")\n",
    "    for node, metrics in summary['nodes'].items():\n",
    "        print(f\"  {node}: {metrics['avg_time']:.3f}s avg ({metrics['executions']} exec)\")\n",
    "    \n",
    "    print(f\"\\nLLM Calls: {summary['llm']['total_calls']}\")\n",
    "    if summary['llm']['total_tokens'] > 0:\n",
    "        print(f\"Total Tokens: {summary['llm']['total_tokens']:,}\")\n",
    "        print(f\"Estimated Cost: ${summary['llm']['estimated_cost']:.4f}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Monitoring is disabled.\")\n",
    "    print(\"To enable, set ENABLE_MONITORING=true in your .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2d9a4b",
   "metadata": {},
   "source": [
    "## Export Metrics to JSON\n",
    "\n",
    "You can export metrics for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6e92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if WorkflowConfig.ENABLE_MONITORING:\n",
    "    from src.agent_workflow.workflow import monitor\n",
    "    \n",
    "    # Export metrics to JSON file\n",
    "    metrics_file = \"query_metrics.json\"\n",
    "    monitor.export_metrics(metrics_file)\n",
    "    \n",
    "    print(f\"Metrics exported to: {metrics_file}\")\n",
    "    \n",
    "    # Read and display\n",
    "    import json\n",
    "    with open(metrics_file, 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "    \n",
    "    print(\"\\nExported Metrics Structure:\")\n",
    "    print(f\"  - Pipeline metrics: {len(metrics['pipeline'])} fields\")\n",
    "    print(f\"  - Node metrics: {len(metrics['nodes'])} nodes\")\n",
    "    print(f\"  - LLM metrics: {len(metrics['llm'])} fields\")\n",
    "    print(f\"  - Execution steps: {len(metrics['steps'])} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498c68aa",
   "metadata": {},
   "source": [
    "## Batch Processing Multiple Queries\n",
    "\n",
    "You can process multiple queries in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441a460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"How many employees work in Sales?\",\n",
    "    \"What is the average order value?\",\n",
    "    \"List all departments\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Processing batch queries...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, query in enumerate(queries, 1):\n",
    "    print(f\"\\nQuery {i}/{len(queries)}: {query}\")\n",
    "    \n",
    "    try:\n",
    "        result = run_nl2sql_query(query)\n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"answer\": result[\"final_response\"],\n",
    "            \"sql\": result[\"generated_query\"],\n",
    "            \"success\": True\n",
    "        })\n",
    "        print(f\"  âœ“ Success\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"error\": str(e),\n",
    "            \"success\": False\n",
    "        })\n",
    "        print(f\"  âœ— Failed: {str(e)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BATCH RESULTS SUMMARY:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "successful = sum(1 for r in results if r[\"success\"])\n",
    "print(f\"\\nSuccessful: {successful}/{len(queries)}\")\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"\\n{i}. {result['query']}\")\n",
    "    if result[\"success\"]:\n",
    "        print(f\"   Answer: {result['answer'][:100]}...\")\n",
    "    else:\n",
    "        print(f\"   Error: {result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e696615b",
   "metadata": {},
   "source": [
    "## Understanding the Workflow\n",
    "\n",
    "The workflow consists of these steps:\n",
    "\n",
    "1. **Parallel Schema Retrieval**: Simultaneously searches vector store and database for relevant tables\n",
    "2. **Query Generation**: Converts natural language to SQL using LLM\n",
    "3. **Query Validation**: Multi-layer validation (safety, syntax, semantic)\n",
    "4. **Query Execution**: Executes the validated SQL query\n",
    "5. **Error Recovery**: If errors occur, automatically attempts to fix the query\n",
    "6. **Result Formatting**: Converts SQL results to natural language response\n",
    "\n",
    "Each step is logged and monitored (if enabled)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b300bb",
   "metadata": {},
   "source": [
    "## Advanced: Accessing State Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974e8832",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Show me product categories\"\n",
    "\n",
    "result = run_nl2sql_query(query)\n",
    "\n",
    "print(\"Complete State Information:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nVector Search Results:\")\n",
    "vector_tables = result.get(\"vector_retrieved_tables\", [])\n",
    "print(f\"  Tables from vector search: {', '.join(vector_tables) if vector_tables else 'None'}\")\n",
    "\n",
    "print(\"\\nSchema Information:\")\n",
    "schema_name = result.get(\"schema_name\")\n",
    "print(f\"  Schema name: {schema_name or 'N/A'}\")\n",
    "print(f\"  Relevant tables: {', '.join(result.get('relevant_tables', []))}\")\n",
    "\n",
    "print(\"\\nValidation:\")\n",
    "print(f\"  Validation result: {result.get('validation_result', 'N/A')}\")\n",
    "print(f\"  Validation error: {result.get('validation_error', 'None')}\")\n",
    "\n",
    "print(\"\\nExecution:\")\n",
    "print(f\"  Execution error: {result.get('execution_error', 'None')}\")\n",
    "print(f\"  Retry count: {result.get('retry_count', 0)}\")\n",
    "\n",
    "print(\"\\nFinal Response:\")\n",
    "print(f\"  {result.get('final_response', 'N/A')[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2126b",
   "metadata": {},
   "source": [
    "## Tips and Best Practices\n",
    "\n",
    "### 1. Query Formulation\n",
    "- Be specific and clear in your questions\n",
    "- Include relevant context (time periods, categories, etc.)\n",
    "- Use standard database terminology\n",
    "\n",
    "### 2. Monitoring\n",
    "- Enable monitoring in development to understand performance\n",
    "- Disable in production if not needed to reduce overhead\n",
    "- Export metrics for analysis and optimization\n",
    "\n",
    "### 3. Error Handling\n",
    "- Always check for `execution_error` and `validation_error` in results\n",
    "- Use try-except blocks for production code\n",
    "- Set appropriate `max_retries` based on query complexity\n",
    "\n",
    "### 4. Configuration\n",
    "- Adjust `MAX_RETRIES` based on your needs\n",
    "- Set `VECTOR_SEARCH_K` based on database size\n",
    "- Choose appropriate LLM provider and model\n",
    "\n",
    "### 5. Performance\n",
    "- Vector search provides faster table identification\n",
    "- Parallel retrieval improves overall performance\n",
    "- LLM choice affects speed and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5195f141",
   "metadata": {},
   "source": [
    "## Integration Examples\n",
    "\n",
    "### Using in a Streamlit App\n",
    "\n",
    "```python\n",
    "import streamlit as st\n",
    "from src.agent_workflow import run_nl2sql_query\n",
    "\n",
    "st.title(\"Database Query Assistant\")\n",
    "\n",
    "user_query = st.text_input(\"Ask a question about your database:\")\n",
    "\n",
    "if user_query:\n",
    "    with st.spinner(\"Processing...\"):\n",
    "        result = run_nl2sql_query(user_query)\n",
    "    \n",
    "    st.success(\"Query completed!\")\n",
    "    st.write(result[\"final_response\"])\n",
    "    \n",
    "    with st.expander(\"View SQL Query\"):\n",
    "        st.code(result[\"generated_query\"], language=\"sql\")\n",
    "```\n",
    "\n",
    "### Using in an API\n",
    "\n",
    "```python\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from src.agent_workflow import run_nl2sql_query\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.post(\"/query\")\n",
    "async def query_database(query: str):\n",
    "    try:\n",
    "        result = run_nl2sql_query(query)\n",
    "        return {\n",
    "            \"response\": result[\"final_response\"],\n",
    "            \"sql\": result[\"generated_query\"],\n",
    "            \"success\": True\n",
    "        }\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad58e1b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The agent_workflow provides a production-ready, configurable solution for NL2SQL queries:\n",
    "\n",
    "âœ… **Simple API**: Single function call  \n",
    "âœ… **Configurable**: All settings via environment variables  \n",
    "âœ… **Robust**: Multi-layer validation and error recovery  \n",
    "âœ… **Observable**: Optional monitoring and metrics  \n",
    "âœ… **Fast**: Parallel schema retrieval  \n",
    "âœ… **Safe**: Multiple safety checks before execution  \n",
    "\n",
    "For more details, see: `src/agent_workflow/README.md`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b835b43",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Customize Configuration**: Adjust settings in `.env` for your needs\n",
    "2. **Try Different Queries**: Test with your specific database\n",
    "3. **Integrate**: Use in your applications (Streamlit, FastAPI, etc.)\n",
    "4. **Monitor**: Enable monitoring to optimize performance\n",
    "5. **Extend**: Add custom nodes or modify existing ones\n",
    "\n",
    "Happy querying! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
